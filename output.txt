Starting watermarked LLaDA model evaluation...
Watermarking parameters: gamma=0.1, amplification=5, watermark_steps=100
Running HellaSwag with watermarking...
llada_dist (model_path=GSAI-ML/LLaDA-8B-Base,cfg=0.5,is_check_greedy=False,mc_num=128,gamma=0.1,amplification=5,watermark_steps=100), gen_kwargs: (None), limit: None, num_fewshot: 0, batch_size: 8
|  Tasks  |Version|Filter|n-shot| Metric |   |Value |   |Stderr|
|---------|------:|------|-----:|--------|---|-----:|---|-----:|
|hellaswag|      1|none  |     0|acc     |↑  |0.5401|±  |0.0050|
|         |       |none  |     0|acc_norm|↑  |0.7273|±  |0.0044|

Running MMLU with watermarking...
llada_dist (model_path=GSAI-ML/LLaDA-8B-Base,cfg=0.0,is_check_greedy=False,mc_num=1,gamma=0.1,amplification=5,watermark_steps=100), gen_kwargs: (None), limit: None, num_fewshot: 5, batch_size: 1
|                 Tasks                 |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|---------------------------------------|------:|------|-----:|------|---|-----:|---|-----:|
|mmlu                                   |      2|none  |      |acc   |↑  |0.6590|±  |0.0038|
| - humanities                          |      2|none  |      |acc   |↑  |0.5962|±  |0.0068|
|  - formal_logic                       |      1|none  |     5|acc   |↑  |0.5397|±  |0.0446|
|  - high_school_european_history       |      1|none  |     5|acc   |↑  |0.8000|±  |0.0312|
|  - high_school_us_history             |      1|none  |     5|acc   |↑  |0.8333|±  |0.0262|
|  - high_school_world_history          |      1|none  |     5|acc   |↑  |0.8439|±  |0.0236|
|  - international_law                  |      1|none  |     5|acc   |↑  |0.8264|±  |0.0346|
|  - jurisprudence                      |      1|none  |     5|acc   |↑  |0.7407|±  |0.0424|
|  - logical_fallacies                  |      1|none  |     5|acc   |↑  |0.7914|±  |0.0319|
|  - moral_disputes                     |      1|none  |     5|acc   |↑  |0.7399|±  |0.0236|
|  - moral_scenarios                    |      1|none  |     5|acc   |↑  |0.4089|±  |0.0164|
|  - philosophy                         |      1|none  |     5|acc   |↑  |0.6656|±  |0.0268|
|  - prehistory                         |      1|none  |     5|acc   |↑  |0.7346|±  |0.0246|
|  - professional_law                   |      1|none  |     5|acc   |↑  |0.4707|±  |0.0127|
|  - world_religions                    |      1|none  |     5|acc   |↑  |0.8012|±  |0.0306|
| - other                               |      2|none  |      |acc   |↑  |0.6881|±  |0.0080|
|  - business_ethics                    |      1|none  |     5|acc   |↑  |0.8000|±  |0.0402|
|  - clinical_knowledge                 |      1|none  |     5|acc   |↑  |0.6981|±  |0.0283|
|  - college_medicine                   |      1|none  |     5|acc   |↑  |0.6474|±  |0.0364|
|  - global_facts                       |      1|none  |     5|acc   |↑  |0.4600|±  |0.0501|
|  - human_aging                        |      1|none  |     5|acc   |↑  |0.6771|±  |0.0314|
|  - management                         |      1|none  |     5|acc   |↑  |0.8058|±  |0.0392|
|  - marketing                          |      1|none  |     5|acc   |↑  |0.9017|±  |0.0195|
|  - medical_genetics                   |      1|none  |     5|acc   |↑  |0.7000|±  |0.0461|
|  - miscellaneous                      |      1|none  |     5|acc   |↑  |0.7739|±  |0.0150|
|  - nutrition                          |      1|none  |     5|acc   |↑  |0.7288|±  |0.0255|
|  - professional_accounting            |      1|none  |     5|acc   |↑  |0.4645|±  |0.0298|
|  - professional_medicine              |      1|none  |     5|acc   |↑  |0.5662|±  |0.0301|
|  - virology                           |      1|none  |     5|acc   |↑  |0.5181|±  |0.0389|
| - social sciences                     |      2|none  |      |acc   |↑  |0.7485|±  |0.0076|
|  - econometrics                       |      1|none  |     5|acc   |↑  |0.4561|±  |0.0469|
|  - high_school_geography              |      1|none  |     5|acc   |↑  |0.8737|±  |0.0237|
|  - high_school_government_and_politics|      1|none  |     5|acc   |↑  |0.9223|±  |0.0193|
|  - high_school_macroeconomics         |      1|none  |     5|acc   |↑  |0.6487|±  |0.0242|
|  - high_school_microeconomics         |      1|none  |     5|acc   |↑  |0.7059|±  |0.0296|
|  - high_school_psychology             |      1|none  |     5|acc   |↑  |0.8349|±  |0.0159|
|  - human_sexuality                    |      1|none  |     5|acc   |↑  |0.7634|±  |0.0373|
|  - professional_psychology            |      1|none  |     5|acc   |↑  |0.6765|±  |0.0189|
|  - public_relations                   |      1|none  |     5|acc   |↑  |0.7091|±  |0.0435|
|  - security_studies                   |      1|none  |     5|acc   |↑  |0.7469|±  |0.0278|
|  - sociology                          |      1|none  |     5|acc   |↑  |0.8010|±  |0.0282|
|  - us_foreign_policy                  |      1|none  |     5|acc   |↑  |0.8800|±  |0.0327|
| - stem                                |      2|none  |      |acc   |↑  |0.6369|±  |0.0082|
|  - abstract_algebra                   |      1|none  |     5|acc   |↑  |0.4400|±  |0.0499|
|  - anatomy                            |      1|none  |     5|acc   |↑  |0.5852|±  |0.0426|
|  - astronomy                          |      1|none  |     5|acc   |↑  |0.7303|±  |0.0361|
|  - college_biology                    |      1|none  |     5|acc   |↑  |0.7986|±  |0.0335|
|  - college_chemistry                  |      1|none  |     5|acc   |↑  |0.5200|±  |0.0502|
|  - college_computer_science           |      1|none  |     5|acc   |↑  |0.5200|±  |0.0502|
|  - college_mathematics                |      1|none  |     5|acc   |↑  |0.3600|±  |0.0482|
|  - college_physics                    |      1|none  |     5|acc   |↑  |0.4510|±  |0.0495|
|  - computer_security                  |      1|none  |     5|acc   |↑  |0.6800|±  |0.0469|
|  - conceptual_physics                 |      1|none  |     5|acc   |↑  |0.6894|±  |0.0303|
|  - electrical_engineering             |      1|none  |     5|acc   |↑  |0.6690|±  |0.0392|
|  - elementary_mathematics             |      1|none  |     5|acc   |↑  |0.7487|±  |0.0223|
|  - high_school_biology                |      1|none  |     5|acc   |↑  |0.8516|±  |0.0202|
|  - high_school_chemistry              |      1|none  |     5|acc   |↑  |0.5616|±  |0.0349|
|  - high_school_computer_science       |      1|none  |     5|acc   |↑  |0.8300|±  |0.0378|
|  - high_school_mathematics            |      1|none  |     5|acc   |↑  |0.5185|±  |0.0305|
|  - high_school_physics                |      1|none  |     5|acc   |↑  |0.4106|±  |0.0402|
|  - high_school_statistics             |      1|none  |     5|acc   |↑  |0.6389|±  |0.0328|
|  - machine_learning                   |      1|none  |     5|acc   |↑  |0.5536|±  |0.0472|

|      Groups      |Version|Filter|n-shot|Metric|   |Value |   |Stderr|
|------------------|------:|------|------|------|---|-----:|---|-----:|
|mmlu              |      2|none  |      |acc   |↑  |0.6590|±  |0.0038|
| - humanities     |      2|none  |      |acc   |↑  |0.5962|±  |0.0068|
| - other          |      2|none  |      |acc   |↑  |0.6881|±  |0.0080|
| - social sciences|      2|none  |      |acc   |↑  |0.7485|±  |0.0076|
| - stem           |      2|none  |      |acc   |↑  |0.6369|±  |0.0082|

Running GSM8K with watermarking...
Running HumanEval with watermarking...
